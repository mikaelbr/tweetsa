\chapter{Material and Methods}
This chapter covers the material and theory for the methods used in this thesis. The first section describes the data that was used to train and evaluate the models that were developed. Most of the data was given by an ongoing workshop, SemEval'13, who hosted a shared Twitter SA task. It is also described how a smaller in-house data set was collected. The last section explains the machine learning algorithms used in the experiments.

\section{Data sets}
Manually collecting information from Twitter would be a tedious task, but Twitter offers a well documented Representational State Transfer Application Programming Interface (REST API) which allows users to collect a corpus from the microblogosphere. Most of the data used in TSA research is collected through the Twitter API, either by searching for a certain topic/keyword or by streaming realtime data. Four different data sets were used in the experiments described below. Three were supplied by the organisers of the SemEval'13 shared task on Twitter sentiment analysis~\citep{WilsonEA:13}, in the form of a training set, a smaller initial development set, and a larger development set. All sets consist of manually annotated tweets on a range of topics, including different products and events.

Tweet-level classification (Task 2B) was split into two subtasks in SemEval'13, one allowing training only on the data sets supplied by the organisers (constrained) and one allowing training also on external data (unconstrained). To this end, a web application\footnote{\url{https://github.com/mikaelbr/tweetannotator}} for manual annotation of tweets was built and used to annotate a small fourth data set ('NTNU'). Each of the 461 tweets in the 'NTNU' data set were annotated by one person only.

The distribution of target classes in the data sets is shown in Table~\ref{tab:datasets}. The data was neither preprocessed nor filtered, and thus contain hashtags, URLs, emoticons, etc. However, all the data sets provided by SemEval'13 had more than three target classes (e.g., 'objective', 'objective-OR-neutral'), so tweets that were not annotated as 'positive' or 'negative' were merged into the 'neutral' target class.

\begin{table}[htb!]
\centering
\begin{tabular}{l|rrrrrrrrr}
\noalign{\smallskip}\hline\noalign{\smallskip}
& \multicolumn{2}{c}{Training} & \multicolumn{2}{c}{Dev 1} &\multicolumn{2}{c}{Dev 2} &\multicolumn{2}{c}{NTNU}  \\
Class & Num & \% & Num & \% & Num & \% & Num & \% \\

\noalign{\smallskip}\hline\noalign{\smallskip}
Negative & 1288 & 15 & 176 & 21 & 340 & 26 & 86 & 19\\
Neutral  & 4151 & 48 & 144 & 45 & 739 & 21 & 232 & 50 \\
Positive & 3270 & 37 & 368 & 35 & 575 & 54 & 142 & 31 \\ 
Total & 8709 && 688 && 1654 && 461 &\\ 
\noalign{\smallskip}\hline\noalign{\smallskip}
\end{tabular}
\caption{The data sets used in the experiments}
\label{tab:datasets}
\end{table}

Due to Twitter's privacy policy, the given data sets do not contain the tweet text, but only the tweet ID which in turn can be used to download the text. The Twitter API has a limit on the number of downloads per hour, so SemEval'13 provided a Python script to scrape texts from https://twitter.com. This script was slow and did not download the texts for all tweet IDs in the data sets, so a faster and more precise download script\footnote{\url{https://github.com/mikaelbr/twitscraper}} for Node.JS was implemented and submitted to the shared task organisers.

\section{Algorithms}

The following section covers some theory for the machine learning algorithms that are used in the experiments for this thesis. First the Naive Bayes classifier is described, and then Maximum Entropy and Support Vector Machines are covered. At the end of the section, two ensemble methods, bagging and boosting are explained.

\subsection{Naive Bayes classifier}
The Naive Bayes (NB) classifier is a practical Bayesian learning model that is easy to understand and implement. For some classification tasks, it has proven to be equally performing to more complex machine learning algorithms like artificial neural networks (\nom{ANN}{Artificial Neural Networks}) and decision trees (\nom{DT}{Decision Trees})~\citep{book:Mitchell}. NB is used for learning tasks where an instance $x$ consists of a number of attribute-value pairs, and the target function $f(x)$ consists of a finite number of values from a set $V$.

The NB classifier is based on an assumption that all the attribute values are conditionally independent given the target value of the instance.
\begin{equation}
\label{equation:nbc}
v_{NB} = \argmax{v_j \epsilon V} P(v_j) \prod_{i} p(a_i|v_j)
\end{equation}

To classify an instance, the classifier uses the Maximum Likelihood Estimation (\nom{MLE}{Maximum Likelihood Estimation}) method to find the ratio of an attribute value and a given target value on the same instance in the training corpus. This means that it has to calculate the probability estimate $P$ for each attribute $a_i$, given the target value $v_j$, as shown in equation~\ref{equation:nbc}. It then assigns the target value as the one that gives the highest product from multiplying all the probabilities $P$ from the training data.

The assumption of conditionally independent attributes makes this classifier best suited for handling bag-of-words models, which are composed by collections of unigrams.

\subsection{Maximum Entropy}

Maximum Entropy (MaxEnt) is a multinomial logistic regression model that allows for classification with more than two discrete classes. It has been used for various natural language tasks, such as POS tagging and text segmentation~\citep{article:nigam}.

The principle in MaxEnt is to model all that is known and assume nothing about that which is unknown. In other words, if you have some knowledge about a domain, choose a model that is consistent with the knowledge, but otherwise as uniform as possible.

The MaxEnt models are feature-based, and in binary classification scenarios it is the same as general logistic reasoning. Unlike NB it has no assumptions of conditionally independence, and can therefore be used with feature selection methods like n-grams and extended unigrams (unigrams with negation support)~\citep{article:go}.

\subsection{Support Vector Machines}

Support Vector Machines (SVM) are often called the large margin classifiers because SVM try to separate learning data with the highest possible margin~\citep{article:fletcher}. By separating classes in the training data with a high margin, it will obtain a better accuracy when classifying unobserved instances. Basically, SVM can only classify binary problems, however by dividing the problem into several subclassifications, SVM can be used for multi-class tasks also.

\begin{figure}[ht]
	\begin{minipage}[b]{0.45\linewidth}
		\centering
		\includegraphics[width=\textwidth]{../img/linear.png}
		\caption[The hyperplane linearly separates the data into two classes.]{The hyperplane linearly separates the data into two classes. The points closest to the hyperplane are the support vectors.}
		\label{fig:linear}
	\end{minipage}
	\hspace{0.5cm}
	\begin{minipage}[b]{0.45\linewidth}
		\centering
		\includegraphics[width=\textwidth]{../img/non-linear.png}
		\caption[An example of a non-linear SVM problem.]{An example of a non-linear problem. A kernel function is used to map these data points into a higher dimensional feature space.}
		\label{fig:non-linear}
	\end{minipage}
\end{figure}

The equation for the separating hyperplane is defined by the closest points to the margin, as seen in~\autoref{fig:linear} These points are called \emph{support vectors}. In cases where the data is non-linear, as in~\autoref{fig:non-linear}, a kernel function is used to project the data into a high-dimensional space where it is linearly separable.

\subsection{Ensemble Learning}

Ensemble Learning is a process where multiple models are used in an ensemble to solve a problem. The thought behind using an ensemble of classifiers is to reflect how we make choices in our real lives. A normal procedure is to collect the opinion from several others, sometime even experts, to support our decisions. This is also what an Ensemble Learning classifier does. Ensemble Learning is itself a supervised learning algorithm, since it's trained and used to make predictions. An Ensemble learner can be a combination of different algorithms, and need not necessarily consist of one specific type. There are mainly two complementary approaches to training these individual classifiers: bootstrap aggregating~(\nom{bagging}{Bootstrap Aggregating}) and boosting. The main difference is how the classifiers in an ensemble use their training data. Each classifier in bagging is trained on a subset of the training data, while in boosting, all classifiers are trained on the same original data set.

\subsubsection{Bootstrap Aggregating}

In the bagging variant, each classifier have an equally weighted vote. To obtain variance in the ensemble, the individual classifiers are trained on a different dataset, called "bootstrap replicate", that is randomly drawn from the original training data set, with replacement. Thus, for a training set with \emph{n} samples, the bootstrap replicate would also have \emph{n} samples, but some samples may appear several times and some samples from the original set may not appear at all.

\subsubsection{Boosting}

Boosting is a method that is used to increase the accuracy of several weak learners. Each classifier in a boosting algorithm is trained on the same dataset. Weights are added to each training instance in the learning set. The weights indicates the importance of an instance to the current classifier~\citep{Freund;Schapire:97}. 

When a classifier fails to predict the correct class for an instance, the weight for that particular instance is increased. So when training the next hypothesis, it will have an increased chance to successfully handle that instance.

In the process of generating hypotheses for the ensemble, each of the classifiers are evaluated and given a weight, as an indicator of its accuracy. When new queries are sent to the boosting algorithm, a voting takes place. Each hypothesis recommends a classification for the query instance, then the weights are summed up and the target class with the highest total weight is chosen.

\chapter{Architecture}
\label{sec:experimentalsetup}

This chapter defines the architecture for the generic Twitter Sentiment Analysis system, and the implemented visualisation applications. Section~\ref{sec:tsaarchitecture}, describes the architecture for the API layer as well as the sentiment classifier server. Section~\ref{sec:visualization_applications}, documents how the visualisation applications are implemented and how the finished product works.

\section{TSA Architecture}
\label{sec:tsaarchitecture}

This section describes the overall architecture and how the system works. First the general system will be described, then the Application Programming Interface~(\nom{API}{Application Programming Interface}) Layer and classification server in turn.  

To make the system as modularized and responsive as possible, the API Layer was written in Javascript, on the Node.js platform, and the sentiment classifier in the Python programming language. Both systems are continuously running servers. This allows multiple services to run simultaneously, both for the API layer and the classifier. The idea is to make the system horizontally scalable.

\begin{figure}[ht]
 \begin{center}
     \includegraphics[width=0.8\textwidth]{../img/NetworkDiagram.pdf}
 \end{center}
 \caption[Architectural overview of the system.]{Architectural overview of the system. The client retrieves data from the Twitter API and uses the classification server for sentiment classification.}
 \label{fig:NetworkDiagram.pdf}
\end{figure}

A client makes a request to the API Layer, with the same interface as the Twitter API service. From there the API Layer will retrieve information from the Twitter API with Hypertext Transfer (or Transport) Protocol~(\nom{HTTP}{Hypertext Transfer (or Transport) Protocol}) requests, iterate over all tweets received, and send them in parallel to the classification server. When the classification server is done processing and classifying the tweet, it is sent back to the API Layer. When the API layer has received all the tweets, it responds to the client with the same JavaScript Object Notation~(\nom{JSON}{JavaScript Object Notation}) data structure as the Twitter API sends out, only with an additional attribute noting the tweet's sentiment. This architecture and application flow can be seen in~\autoref{fig:NetworkDiagram.pdf}. 

\subsection{API Layer Extension}

To be able to have a scalable and responsive solution, the API Layer was written using the Node.js platform. Since Node.js uses JavaScript as programming language, the JSON data retrieved from the Twitter Representational state transfer~(\nom{REST}{Representational state transfer}) and Streaming API are easily manipulated and passed around. 

The API Layer works as a thin layer extending the Twitter API. This means that the interface used by Twitter, with all defined options and appropriate methods, is reflected through the API Layer. The main benefit is that all documentation for the Twitter API also documents most of this extended API Layer.

For authentication, an application is registered with a developer account at the Twitter Developer site. This creates OAuth credentials, which is used to identify the application~\citep{site:oauth}, and to gain access to the Twitter data. For this implementation, the data is retrieved using the OAuth access for the application, not at user level. 

\subsubsection{Architectural Flow}

\begin{figure}[!ht]
 \begin{center}
     \includegraphics[width=0.8\textwidth]{../img/APILayerArcitechture.pdf}
 \end{center}
 \caption[Architectural overview of the API Layer.]{Architectural overview of the API Layer. A request is handled by the server, sending it to routing where it is processed and sent to service look-up. If a service is found, a request is sent to the Twitter API and the received data is extended by the Twitter Data Handler module to contain a sentiment. When all of the Twitter data are extended, the data is given as a response to the requesting client.}
 \label{fig:APILayerArcitechture.pdf}
\end{figure}

When a request from a client is made, the request gets processed by the server and the routing module determines what the client is looking for. When the proper service is found, the client-specified parameters are sent directly to the Twitter API, using the Twitter Data Handler module (\nom{TDH}{Twitter Data Handler}). The TDH module then iterates over all found tweets, and sends them in parallel to the classification server. When a tweet has been processed by the classification server the classified sentiment is sent back to the TDH module and the original tweet object is extended to contain a property with the sentiment. When all tweets are classified, the TDH module passes the extended twitter data to the render module. The render module renders the JSON data and sends it to the client with appropriate HTTP headers set. This application flow can be seen in~\autoref{fig:APILayerArcitechture.pdf}.

If there is an error during any part of the process, the error is caught by the routing module, and the error is rendered as a JSON object, in the same manner as it would be by the Twitter API. 

When using both the Twitter REST API and Streaming API, there is a high level of asynchronism. Especially when streaming, it is impossible to predict when the next tweet is received. Due to this the system designed needs to be able to handle this dynamic data flow. Node.js is an event-driven platform and has a natural support for asynchronous data. 

All internal and external message passing in the API Layer is asynchronous. When requesting Twitter for data, an event is triggered when that data is ready and all tweets are separately sent to the classifier. By sending all tweets separately in parallel, classification of the entire set of tweets does not take much longer than classifying only one tweet. 

When streaming, the TDH module opens a connection to the Twitter API, but never closes it. There is a continuously open connection to the Twitter server, which is feeding the TDH module with single tweets as they get stored in the Twitter system. From the first received tweet, a connection to the requesting client is opened by the render response module. This connection will also remain open. In this way there is an open connection between the client and the API Layer as well as between the API Layer and the Twitter API. The API Layer works as a middleman, taking in tweets, classifying them, and streaming them to the client. By running this entire process asynchronously, the system can process data independently of when it is published.


\subsection{Sentiment Analysis Classifier}
\label{sec:classifier_arch}

Python is computationally stronger than Node.js in many ways. Additionally, it is much more mature. There are a lot of well documented packages for handling various tasks. Scikit-learn (\nom{sklearn}{Scikit-learn python module}) is one of these packages. sklearn is a package built on top of the Python packages numpy, scipy and matplotlib. sklearn integrates machine learning algorithms as SVM, NB, MaxEnt and more. sklearn implements solutions for doing feature extraction, grid searching, cross validation and a lot more for analysing text. Thus it is a good choice for the process of sentiment analysis. As a dynamic typed language, Python allows for rapid development and prototyping. These attributes are some of the reasons Python is a good fit for the present system. 

The Sentiment Analysis Classifier system runs as a server waiting for requests. The HTTP method POST is used for a client to send a \textit{stringified} tweet object to the server. Stringify is a JSON method for returning a serialized object represented by a string. The classification server converts this string to a Python dictionary. The response will be a string with the sentiment classification, that is, either \textit{positive}, \textit{neutral} or \textit{negative}. The classification scheme can be extended if necessary. 

The classifier server can be initialized with different settings for classification strategy, what port to run at, what training data to use, and whether or not to show debug data. This allows for multiple servers running at the same time, with different settings. Running multiple server instances makes it easier to compare different classification strategies. Two servers could run side by side, and a test framework could use the two servers to classify the same tweets for a comparison.

When the server is initiated, the selected model is trained by having and made available to be used by the classification server. 

The classification server uses a pool of child processes. For each receiving tweet, it spawns a new child from this pool and in this process the tweet is classified. This way the classification server can process several tweets in parallel, which helps the one-to-one relationship between a tweet on the classification server and the same tweet on the API Layer.

\subsubsection{Architectural Flow}

\begin{figure}[!htb]
 \begin{center}
     \includegraphics[width=0.8\textwidth]{../img/ClassifierArcitechture30.pdf}
 \end{center}
 \caption[Architectural overview of the classification server.]{Architectural overview of the classification server. On server start, a model for predicting sentiment is generated. When a request from the API Layer is made to the POST Server, a child processes is spawned. The tweet text is extracted and sent into the model for classification. If the classification model is a one-step process, the classifier returns to the sentiment provider with either a neutral, positive or negative classification. If the generated model is two-stepped, the tweet is first classified as either neutral or subjective. If it is neutral, it is returned to the API Layer, if it is subjective, it is sent to the next step and the result from that step is returned to the sentiment provider.}
 \label{fig:ClassifierArcitechture}
\end{figure}

\begin{figure}[!htb]
 \begin{center}
     \includegraphics[width=0.8\textwidth]{../img/ClassifierArcitechture30Boosting.pdf}
 \end{center}
 \caption[Architectural overview of the classification server with boosting.]{Architectural overview of the classification server with boosting. On server start, the boosting model for predicting sentiment is generated with a set of sub-models. When a request from the API Layer is made to the POST Server, a child processes is spawned. The tweet text is extracted and sent into the model for classification. All models predicts a sentiment and sends the sentiment to voting. For voting the boosting model selects the sentiment with highest score and returns this to the API sentiment provider.}
 \label{fig:ClassifierArcitechtureBoosting}
\end{figure}

The Sentiment Provider module from the API Layer makes a request to the classifier's POST Server. The POST server translates the string to a Python dictionary and passes the information down to the Child Process Spawner. A new process is spawned and, using the module generated when initiating the server, the tweet is classified and returned to the API Layer.

When the classification model is trained on the server initialization, various text filters, normalizations and other pre-processing methods can be utilized, as seen in figure~\ref{fig:ClassifierArcitechture}. The model can be generated as either a one-step process, two-step process or a combination using boosting. 

If a one-step model is used, one algorithm is used to classify the tweet as either negative, neutral or positive. If a two-step model is used, the tweet is first classified as either subjective or neutral in the subjectivity classification step. If it is neutral, the model returns with the classification. If the result is subjective, the tweet is sent to the polarity classification step, where the result can either be negative or positive. The end classification is returned to the API Layer.

When using the boosting model, a set of sub-models is generated and all used in conjunction to predict a sentiment of a tweet. All sub-models predicts and sends the classification to a weighted voting mechanism. The final classification is the result of the vote. This process is visualised in figure~\ref{fig:ClassifierArcitechtureBoosting}.

\subsubsection{Classification Model Structure}

The classification models are implemented by wrapping machine learning algorithms from sklearn in a inheritance based class structure. By having every model inherit from a base model, the interface is the same across every model, and the system can use the model without having knowledge what kind of algorithm it uses. An overview of this structure is presented in figure~\ref{fig:ModelsStructure}.

The base parent model implements methods for training the machine learning algorithm and for predicting either a set of documents or one document. For one-step algorithms as NB, SVM and MaxEnt, these generic methods can be used, but the two-step and boosting models have their own implementation. 
 
\begin{figure}[!ht]
 \begin{center}
     \includegraphics[width=\textwidth]{../img/ModelsStructure.pdf}
 \end{center}
 \caption[Classification Model Structure Overview]{Overview of how the models are built and connected. There is a base model class implementing a method for predicting and training. All models extends from this base model. The models for NaiveBayes, SVM and MaxEnt uses the base model's implementation of train and predict, whilst the TwoStep and boosting models implement their own. The interface for each model is the same.}
 \label{fig:ModelsStructure}
\end{figure}


\clearpage
\section{Visualisation Applications}
\label{sec:visualization_applications}
To test and give example of how to use the generic system designed in~Section~\ref{sec:tsaarchitecture}, different visualisation applications were implemented. Each of these applications is described in their own sub section in this section. The sub sections are divided into describing how the applications are implemented and the finished product.

\subsection{SentiMap: Geo-location based streams}

To show how the streaming API and geo-location can be used to analyse sentiments for a location in real-time, SentiMap was developed. SentiMap is a visualisation tool showing the distribution of sentiments across the states of USA with or without a search query. When a new tweet is posted, within the USA, it is used to change the colour of the state it originated from. SentiMap can show the specifics of a state, with the number of positive and negative tweets, and the total of tweets registered.

SentiMap also tracks changes in sentiment in the entire USA per second. If a major event happens, the time line could show a change in sentiment across the country. The sentiment difference is calculated by taking the number of positive tweets subtracted by the number of negative tweets in a given second. 

\subsubsection{Implementation}

Most of the application is implemented on the client side, and thus running in the browser. There is a thin server side code base running, handling the stream. In this section, the server will be described first, then all details about the client implementation is covered. 


\textbf{Server side implementation} \\

The client side (browser), can not connect to a Twitter stream by it self. So to be continually fed tweets in real-time, a server implementation is necessary. SentiMap's server handles the following:

\begin{enumerate}
\item Connect to the API Layer stream.
\item Open a WebSocket connection for clients to connect to. 
\item Start a HTTP server, serving HTML, JavaScript~(\nom{JS}{JavaScript}),  Cascading Style Sheets~(\nom{CSS}{Cascading Style Sheets}), images and other resources. 
\item Serve the clients connected to the WebSocket with tweets.
\end{enumerate}

Since the API layer is designed as a thin layer on top of the official Twitter API, the interface is the same. This means that programming libraries designed to interact with the Twitter API, can also communicate with the API Layer. SentiMap uses a forked (branched/copied a open sourced project) Node.JS module called nTwitter\footnote{\url{https://github.com/AvianFlu/ntwitter}}. The only alteration made on nTwitter is to change the base URL for the API location from pointing to Twitter's servers to direct to the API Layer server instead.

The server opens a WebSocket connection to allow clients to stream tweets from the forked nTwitter module. WebSockets\footnote{\url{http://en.wikipedia.org/wiki/WebSocket}} is a technology used to accomplish a full-duplex connection over the Transmission Control Protocol~(\nom{TCP}{Transmission Control Protocol}). This means that a server can push information to a client, without the client requesting it first, as with regular HTTP connection. There are two channels of communication opened for the WebSockets. One channel for streaming all tweets from the US, and one channel used to commute tweets related to a search. All clients share a connection to the non-query based stream, but for a search each client has its own connection. If there are no clients connected to the non-query based stream, the connection to the API Layer is closed, and only opened again if a client connects to the WebSocket.

The server uses a simple Node.js HTTP module to serve static file content to clients. The static content is HTML files, JavaScript libraries and code bases, images and styling files.

When a client connects to the WebSocket, on either channel, it gets fed tweets in real time. The clients receive full tweet objects directly from the API Layer. This way the clients them self can choose to do with the tweets and use them for multiple purposes at once. All logic regarding computation of sentiment statistics, graphing and logging is handled by each client.

\textbf{Client side implementation} \\

The client side uses a MV* design pattern to accomplish modularity and structure. A Model-View-*~(\nom{MV*}{Model-View-*}) design pattern, resembles a classical Model View Controller~(\nom{MVC}{Model View Controller}) pattern, but uses no controllers. Instead it relies more on views to handle the logic. To help with this design pattern, a JavaScript framework called Backbone.js\footnote{\url{http://backbonejs.org/}} is used. In later years Backbone has become a very popular framework to use on the client side for achieving structure in large scale applications. Backbone is a small framework and works in smaller applications as well as big corporate ones.

Every application function is its own independent module, and as such is pluggable. To support this modularity, the code is be separated into three different code structures:

\begin{enumerate}
\item Models
\item Collections
\item Views
\end{enumerate}

Models holds values and operations to interact with these values. For the SentiMap application, there are three different models; $State$, $TimelineStats$, and $TweetCount$. 

The $TimelineStats$ model holds a two dimensional array with time stamps and sentiment difference as value, and an operation to append attributes to this value. When a set of time stamp and sentiment difference is added to the array, the model broadcasts this change to any listeners, by using \textit{events}. 

The $TweetCount$ model operates the same as $TimelineStats$, but instead of having an array as a value, it simply stores an integer. $TweetCount$ offers operations to increase by one or reset the integer. When the integer is changed, the model announces so through events. Both the $TimelineStats$ and $TweetCount$ models are only intended to be initiated once, unlike the $State$ model.

For each state in the USA, an object is created from the $State$ model. This model holds values for state ID (name abbreviation. e.g. NY for New York), number of positive and negative tweets for the given state. The model has operations for increasing both the negative and positive counter values by one. The model triggers an event when the values change. 

A collection is simply a collection of models. In the SentiMap applications, the only collection is states which holds all the state model objects. Collections offers operations for fetching objects based on ID. This way, a collection can retrieve the model object for New York, based on the abbreviated name. 

Views handles most of the logic and interactions with the end user. A view can represent a model or collection, but does not require to do so. A view is coupled with a HTML element in the Document Object Model~(\nom{DOM}{Document Object Model}) and can be used to render the contents of a model or collection of models into this DOM structure. A view can be looked at as a pluggable module. SentiMap consists of several views. Below is a list of the essential ones and a description of the view's role in the system.

\begin{description}
\item[App] \hfill \\
The App view is the heart of the application. It loads and initiates all modules (views). When App is initiated, the map, timeline, tweet counter and stream view is initiated as well. The App view has an operation (method) for switching between a query based stream (search) or non-query based.

\item[PublicStreamView] \hfill \\

The PublicStreamView and SearchView is strongly related. PublicStreamView handles the streaming of tweets when no search query is defined. PublicStreamView connects to the non-query based channel of the servers WebSocket, and attaches an operation to respond when the server pushes a new tweet. This response operation reads the tweet and based on the tweet location property, determines what state the tweet originates from. Using the ID for the state, the state model object is fetched from the state collection. Depending on whether the sentiment classification of the tweet is positive or negative, the response operation triggers the increase negative or positive tweet method on the model.

The PublicStreamView module also has methods for disconnecting from the server WebSocket, and removing the generated HTML view from the DOM.

The response handler broadcasts a global event each time a new tweet is received. 

\item[SearchView] \hfill \\

The SearchView works almost exactly the same way as the PublicStreamView. If the App triggers a change between modes (from non-query based, to search), the SearchView connects to the search channel on the WebSocket and communicates on which query it would like to receive tweets related to. The SearchView and PublicStreamView shares the response handler on a new tweet.

\item[MapView] \hfill \\

To render out a map of the USA and connect each state with a view, the MapView is initiated. The MapView is the view of the states collection. When initiated, the MapView renders out a map of the USA consisting of individual parts for each state. MapView creates a StateView object per state in the map and attributes these objects with their corresponding state models.

\item[StateView] \hfill \\

A state view is created by the MapView, and has two attribute values; a state HTML object from the map, and the state model object. 

On initialization, the StateView listens for any events on the attached model. If a state model changes its polarity (either positive or negative values are increased or reset), two operations get triggered; change colour on the map for the given state, and if the state specific statistics is visible, update the statistics.

The state view also handles the presentation of the state specific statistics. If a state on the map is clicked, the StateView of that state hides the current detailed statistics (if any), and shows the statistics for the clicked state. Before showing the chart, it makes sure that the details are up to date. 

\item[TweetCountView] \hfill \\

The TweetCountView is a simple view, initiated by the App view. On initialization, the TweetCountView attaches a view render operation on the new tweet event broadcasted by the public stream and search stream response handlers. This view renderer updates a counter on the site, informing the end user on how many tweets the SentiMap as registered on the current map. 

\item[TimelineStatsView] \hfill \\

The TimelineStatsView is initiated from the App view, and has the $TimelineStats$ model attached to it. The TimelineStatsView renders an empty graph when it is initialized. When new sentiment difference data is pushed to the attached model, the generated graph is updated to reflect these changes. The TimelineStatsView graph is updated every second. 

\end{description}

\subsubsection{Working Product}

\begin{figure}[htb!]
\begin{center}
 \includegraphics[width=0.8\textwidth]{../img/sentimap_screenshot.png}
 \caption{Screen shot of the SentiMap system running.}
 \label{fig:sentimap_screenshot}
\end{center}
\end{figure}

The SentiMap applications consists of three main components; an input box for search, a map of the USA with an optional details view and a timeline graph (see Figure \ref{fig:sentimap_screenshot}). Per default, the search box, is empty which results in the map being updated with tweets without any constraints regarding topic or query. If a query is typed into the search box and the return key is pressed, the map view cleared for any colour and statistics, and the map is updated with sentiments from tweets related to the submitted query (see Figure~\ref{fig:sentimap_screenshot_search}). 

\begin{figure}[htb!]
\begin{center}
 \includegraphics[width=0.8\textwidth]{../img/sentimap_screenshot_search.png}
 \caption{Screen shot of the SentiMap when searching for a query.}
 \label{fig:sentimap_screenshot_search}
\end{center}
\end{figure}

When a tweet is received, the state from where the tweet has its origin updates its colour, to reflect the change in sentiment based on the classification of that given tweet. A state where there are only negative tweets has a deep red colour, and a state with only positive tweets is clear green. If there is the same amount of positive and negative tweets, the colour of the state will be light grey. For more positive or negative a state is, the more deeper is the colour of the state. I.e. if a state is 55\% positive it is filled light green, and if a positive tweet from that state is registered, the state colour changes to a slightly more darker green.

By default, no details from a specific state is shown. But if a user clicks on a state, a pie chart is added to the right of the U.S. map. This pie chart shows the details of sentiment on a given state, and the total of tweets registered from that state. This pie chart also updates in real time.

The timeline graph on the bottom on the page, reflects the sentiment difference over time in the entire U.S.. This graph is updated every second, so if the on that second there is registered 18 positive tweets and 12 negative tweets, the graph will show the value 6. If there are no tweets registered for a given time, the graph shows the value 0. Hovering over a point on the x-axis of the graph will show the details of that value, as seen in~Figure~\ref{fig:sentimap_screenshot_timeline}.

\begin{figure}[htb!]
\begin{center}
 \includegraphics[width=0.6\textwidth]{../img/sentimap_screenshot_timeline.png}
 \caption[SentiMap timeline screen shot]{Showing the sentiment difference (positive minus negative sentiments) on that exact second from the streamed data.}
 \label{fig:sentimap_screenshot_timeline}
\end{center}
\end{figure}

The SentiMap always starts from scratch on initialize. So refreshing the page or when opening it for the first time, the map has no values and the time line is set to nil. All statistics and colours reflects sentiments from the second a user initializes the application.

As the SentiMap application is designed to be open over a long period of time, the background image of the application changes to a random nature photography every 30 seconds. This to give an extra visual stimuli and to make the application prettier.



\subsection{Tweet Searching}

The Twitter Search API is another popular service that allows for developers to search the Twitter corpus for recent tweets on a given keyword or topic. To show how to use this Search API with our classification server, a demonstration application called SentiGraph, was developed. SentiGraph consist of a chart and a Twitter timeline that shows the sentiment for each of the tweets in the chart. The chart is a combination of a pie chart, and a bar chart, where both are divided into positive, neutral and negative tweets. The sentiment of the tweets is indicated with red (negative), blue (neutral) and green (positive) colours.

\subsubsection{Implementation}

SentiGraph is a light weight web application that runs exclusively in the client's web browser. It consist of three main views: a search field, a combined chart, and a Twitter timeline. The communication between the application and the API Layer is through Asynchronous JavaScript and XML~(\nom{AJAX}{Asynchronous JavaScript and XML}) technologies. AJAX is used to request and receive the response from the classification server. By using AJAX for communication, the views can be updated with new data without reloading the entire application.

The tweets shown in the timeline includes the tweet text, the date it was published, the author's profile picture and the sentiment classification. All these data are extracted from the tweet JSON object provided by the API layer. The tweets are returned from Twitter API in a chronological order, so when the tweets are rendered they are prepended to the HTML container element to show the most recent tweet first.

A JavaScript library called Highcharts was used to render the combined pie and bar chart. Highcharts offers intuitive and interactive charts written in HTML and JavaScript, and was a good fit for this task. 

The application uses CSS for responsiveness, so it fits different screen sizes. On large screens and resolutions the presentation is divided into two columns, but when the browser window is minimized to below 1080 pixels, the timeline in the right column is moved to the left, so it appears below the chart view.

\begin{figure}[htb!]
\begin{center}
 \includegraphics[width=\textwidth]{../img/screenshot_sentigraph.png}
 \caption[SentiGraph screen shot]{Screen shot of the SentiGraph system working, the same day as Manchester United confirmed Sir Alex Fergusons retirement. Showing overwhelming positive tweets.}
 \label{fig:sentigraph_screenshot}
\end{center}
\end{figure}

\subsubsection{Working Product}

SentiGraph allows the user to define a search query and the number of tweets to be returned. The maximum limit supported by the Twitter API is 100 tweets per query. The returned tweets are processed in JavaScript, and for the timeline view, each tweet's HTML container element are given a CSS colour code to indicate its sentiment. In addition to colouring the container, the script also inserts the author's profile picture, and the date and time the tweet was published. The script waits for all data in each tweet container to be completely downloaded before it renders them in a chronological order. While the application is downloading the data, a loading screen appears in the timeline view. This is mainly to avoid collapsing HTML elements and design flaws because of missing data, but it is also an indication that the application is busy.

The combined pie and bar chart supports some interaction from the user. When clicking one the bars in the bar chart, it shows how many tweets that are predicted as the selected class. By clicking one of the sectors in the pie chart it will display the percentage of tweets in that class.

\subsection{Comparing Queries: SentiStack}

SentiStack is an application to easily compare sentiments between an arbitrary amount of search queries. SentiStack uses the Twitter Search API to retrieve data, and visualises the data as a bar stack per search query. If there is three queries, three bar stacks will be presented in the graph. A bar stack consists of three values; neutral tweets, positive tweets and negative tweets. See a screen shot of the final product in figure~\ref{fig:sentistack_screenshot}.


\begin{figure}[htb!]
\begin{center}
 \includegraphics[width=\textwidth]{../img/sentistack_screenshot_full.png}
 \caption[SentiStack screen shot]{Screen shot of the SentiStack system. Showing a comparison of iPhone, Android and Windows Phone. The graph indicates that there are most positive tweets about Android.}
 \label{fig:sentistack_screenshot}
\end{center}
\end{figure}


\subsubsection{Implementation}

Like SentiGraph, SentiStack is a client side application, and does not require any server side code base. This means that the application can be easily distributed and run locally without any server running to execute the code. 

There are two different aspects to the SentiStack code: input queries, and output graph. Communication with the input form happens through events. When the SentiStack system is initiated, it listens for three events: when a new query is requested, when the "toggle input boxes" button is clicked, and when the "Compare" button is triggered. If one of these events are triggered, an attached method will respond and execute appropriate code; either append input box, hide input boxes or initiate comparison and present the result as a graph.

When the "Compare" button is pressed, the system extracts each query from the input boxes, and constructs a query list. This query list will be iterated and a total of 200 tweets from each query will be retrieved from the Search API using AJAX. As the API responds in JSON, the data can be easily parsed and manipulated. All results from the queries are accumulated in a hash map using the query as a key and a list of the sentiment distribution for that query (e.g. 70 neutral, 70 positive and 60 negative) as a value. When every API request is done, the presentation method is triggered.

The presentation method uses the accumulated data hash map as a source and generates a graph based on that information. For each key in the hash map, a bar stack is generated with the value as distribution for the parts of the stack. The search queries (hash map keys), is used as labels for the graph.

If compare is triggered again, the system will reset (clearing the data hash map and query list) and start the entire process again.

\subsubsection{Working Product}

When opening the SentiStack system, an empty input box is shown, without any graph. The graph will only appear when requested by the "Compare" button. When entering queries in the input boxes and pressing "Compare" the graph will be generated and presented as visible in~figure~\ref{fig:sentistack_screenshot}. 

To add a new query to the system, the "Add Query" link is used. When pressing the link, the last input box is cloned and the cloned box is appended to the list without any value. This process is shown in~figure~\ref{fig:sentistack_addquery}. There are no limitations of the number of queries that can be added, but if there are many of them, the query labels can be hard to read in the graph. If there are many queries, the graph will be pushed down on the page. To avoid this, the "Toggle hide" button can be used. This button toggles the visibility of all except the first input boxes. 

\begin{figure}[htb!]
\begin{center}
 \includegraphics[width=0.7\textwidth]{../img/sentistack_addquery.png}
 \caption[SentiStack add new query screen shot]{Screen shot of the SentiStack system when adding a new query. Figure shows the system after "Add Query" is pressed. The added input box gains focus and is ready to receive query.}
 \label{fig:sentistack_addquery}
\end{center}
\end{figure}

Details for the different queries is visible by hovering over a given bar stack in the graph. The details consists of the number of positive, negative and neutral tweets, as well as the percentage for each of these classifications. This detailed view can be seen in~figure~\ref{fig:sentistack_details}.

\begin{figure}[htb!]
\begin{center}
 \includegraphics[width=0.5\textwidth]{../img/sentistack_details.png}
 \caption[SentiStack detailed view screen shot]{Screen shot of the SentiStack system  when hovering over a bar stack and showing the details for a given query.}
 \label{fig:sentistack_details}
\end{center}
\end{figure}