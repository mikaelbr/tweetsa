\chapter{Discussion}

In the introduction two main goals were introduced for this Master's Thesis:

\begin{description}

\item[G1] \textbf{Experiment with different methods for doing sentiment analysis}
	
\item[G2] \textbf{Develop tools for visualising sentiment classified tweets}

\end{description}

In this section we will discuss whether or not we succeeded in reaching these goals. The first section handles G1 and the second section discusses G2. The generic system architecture is an important part of achieving making the visualisation applications, and thus it is discussed in the latter section.

\section{G1: Experiment with different methods for doing sentiment analysis}

In this section we will discuss if whether we succeeded with our first goal or not. The first goal stated that we should try different methods of classifying sentiments on short messages. 

The experiment description from~section~\ref{sec:experiment} show that we used grid searching on different machine learning algorithms and combination of algorithms to classify sentiment. A total set of 13 different models were thoroughly tested with a large training set. Our system generated graphs and plots comparing the different models, both on accuracy, F1-score, recall, precision and their confusion matrix. This comparative view allowed us to find what model performs the best. 

In our experiments we found that MaxEnt and SVM perform best in regards to accuracy. 

\textcolor{green}{
	Discussion of results / experiments.
	Notes: 
		- SVM vs MaxEnt.
		- NaiveBayes (poor results)
		- Discuss contributions
}

\section{G2: Develop tools for visualising sentiment classified tweets}

We are satisfied with the way the generic system architecture is built. By just extending the Twitter API, no API documentation is needed, and if you are familiar with the Twitter API, you don't have to re-learn any thing. In addition, if there is a system all ready integrated with Twitter data, the migration to our system is simple; simply swap the entry URL point from the Twitter API base URL to our system base URL. 

The current implementation of the API Layer is simplified in regards to authentication. The API Layer has no OAuth server, but rather uses it's own credentials to connect to Twitter. This means, if 10 different users do 30 requests each, Twitters request limit will engage and our API Layer will be put on hold until next window of requests. A better solution would have been to implement a mirror of Twitters OAuth server and pass on the received credentials to Twitter. This way each end-user or application client would have their own pool of requests. 

One important point when designing the generic system was to have it as fast as possible. This to be able to handle large amount of tweets when streaming or simply searching with a high count limit. In some cases a client can request 1000 tweets at once. This required a system that can operate in parallel and handle asynchronous connections. The way our system was built, the API layer works independent of the classification server and each request is parallel and asynchronous. This maximize the number of tweets we can handle and reduce the collected wait time for the client. This solution works great for the applications we have built and for up to 5 clients running simultaneously, but the system has not been tested with any more clients or stress-tested in any way. A stress-test might show a bottleneck or a weakness in the system that is not apparent at this point. 

\subsection{SentiMap}

The SentiMap application show interesting information and distribution of tweets a cross the USA. It is easily capable of handling at least 50 tweets per second, and updates the map's colour scheme for each tweet. Every tweet is grouped by state, so the system looses some information in regards to locality. It could have been interesting to add more details to the map, showing the exact origin of a Tweet in addition to it changing the state sentiment indication colour.

When opening SentiMap now, you start out from scratch. There is no history or storage for the tweets. If you were to open SentiMap and have it classify 1000 tweets, refreshing the application will remove these 1000 tweets. Adding a local storage for these tweets, could provide some usefulness. Also concatenating search data with stream data could be useful, starting the application with some initial data. If some big event happens now, a user has to be quick to open SentiMap to see the sentimental development. 

There is no automatic way of plugging in a different country to the SentiMap application, but the architecture allows for easy system extension. By having defined a clear MV* architecture, each module is fairly independent of each other, and can thus be replaced with different modules. To make this even easier, a plug-in system could have been designed and documented. 

By using WebSockets to provide data from the API Layer, a continuously connection is established. This means that if the API Server goes down, or the visualisation application back-end server restarts, the application will automatically reconnect without any user action. E.g. if you open SentiMap on a laptop, closes this laptop, and then re-open it, SentiMap will reconnect and start showing data again. This means you can have the client open over a long, long time, if necessary.   

\subsection{SentiSearch}

\textcolor{green}{Discussion of sentisearch/sentigraph app.}


%\textcolor{blue}{(8-10 pages) In this chapter you assess your results. Identify your contributions. Possible theory 
%building (establish cause-effect). Compare to other work described in chapter 2. Suggestions for improvements. Discuss 
%construct-, internal-, external- and conclusion-validity. The major challenge in this chapter is usually which axis you 
%want to structure your discussion around: research questions, contributions or studies. Find what works best for you 
%and your studies.}
%
%\textcolor{green}{Evaluation of research questions}
%
%\textcolor{blue}{If you did not answer these questions in the results chapter, now is the time to revisit.}
%
%\textcolor{green}{Evaluation of Contributions}
%
%\textcolor{blue}{How does our contributions fit with the state of the art we described in chapter 2? Do they extend the 
%field? In what way? How do your contributions compare to your research questions? Do you have your own reflections on 
%the contributions.}
%
%\textcolor{green}{Evaluation of Validity Threats}
%
%\textcolor{blue}{What are the major threats to our research? Mention the major threats like:}
%
%\begin{list}{$\bullet$}{}
%  \item Internal Validity 
%  \item External Validity
%  \item Construct Validity
%  \item Conclusion Validity
%\end{list}
%
%\textcolor{blue}{Note that you might have to discuss these separately for each study, and every validity might not be applicable depending on what research method you have used.}
%
%\textcolor{green}{Reflections on the research context}
%
%\textcolor{blue}{Optional. But it is often good to reflect on the (project) context of your research and how it has 
%affected you and your research.}