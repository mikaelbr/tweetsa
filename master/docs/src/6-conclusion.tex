\chapter{Conclusion}
We tested three different base machine learning algorithms: Na\"{i}ve Bayes, SVM and MaxEnt, in addition to combining them for doing two-step classification and boosting with voting for sentiment. From experimenting with these setups, we found that machine learning algorithms perform well for domain semi-independent classification of sentiment.

Our experiments show that SVM and MaxEnt in a single step classification performs best. Given the confusion matrices and results on different data sets, it seems that SVM performs better than MaxEnt. But the neutral-heavy development set caused MaxEnt to perform better than SVM while doing a complete full grid search across multiple values.

Notably, both systems perform well on the out-of-domain data represented by the SMS messages, which is encouraging and indicates that the approach taken really is domain semi-independent. This was also reflected in the rankings of the two systems in the shared task of SemEval'13: both were on the lower half among the participating systems on Twitter data (24th/36 resp. 10th/15), but near the top on SMS data, with the constrained system being ranked 5th of 28  and the unconstrained 6th of 15.

As emoticons were proven informative features, support for Emojis as feature would be an improvement. This would give better performance to applications like SentiMap, that processes only tweets with a geolocation attached to it, i.e., it supports only tweets sent from a mobile device, and possibly an Apple product that uses these Emojis.

By reducing the training set, we obtained better classification for negative and positive tweets separately, but when the number of instances was reduced to a perfect balance between positive, neutral and negative classes, the total number of tweets was too low to train a well-performing classifier. A larger dataset would reveal if training with more balanced data would give a better performing classifier.

The architecture proposed for this system performs well on regular REST API requests, but is also capable of streaming and classifying several tweets per second in real-time. By extending the Twitter API and having the same end point interface, no additional documentation is needed for the API. Existing libraries and programming language specific API wrappers can be used to retrieve information from our API Layer by only changing their URL connection point. 

We found that the sentiment data can be used for visualisation in different practical views. Since Twitter has a lot of meta data attached to each tweet from the REST API, the possibilities for making visualisation applications are huge. With relatively simple steps, one can make applications for showing accumulated sentiments based on a search query, or show changes in sentiment across a country.

The SentiStack visualisation application can be used to compare sentiments on different queries, but seems too generic to handle predictions of such a complex contest as Eurovision Song Contest. ESC has many different aspects as some voting trading and panels of judges that make it difficult to predict the outcome by only using Twitter data. The SentiStack system also just uses 200 tweets per query, to accommodate for the Twitter API request limit, which seems too little to be representative.

\section{Contributions}

In this project we have defined the state-of-the-art for Twitter Sentiment Analysis systems, and implemented a generic system with an architecture capable of classifying many tweets per second in a live stream. We found that, by extending the Twitter API and just attaching a value for sentiments, the data can easily be used to implement visualisation applications, or extending existing Twitter-based systems. 

We have tested different machine learning algorithms, reported to work well with Twitter Sentiment Analysis, and found that SVM and MaxEnt performs well on domain semi-independent short messages.

The development of the visualisation applications shows how Twitter sentiment can be used to get opinions on different topics, keywords or from certain locations. It also shows how the combination of the Twitter API and a generic architecture can be used to easily develop different applications that utilize the data produced by the classification system.

\section{Future Work}

An obvious way to extend this work would be to add other classification algorithms to the grid search, e.g., Conditional Random Fields or more elaborate ensembles. There are also several
features and feature selection methods that could be investigated, such as POS-tagging, like~\cite{article:pak}, and a less na\"{i}ve way of handling negation. Rather than the simple treatment of negation used here, an approach to automatic induction of scope through a negation detector~\citep{CouncillEA:10} could be used. Relational features could also be added, as shown by~\cite{karlgren2010between} and~\cite{johansson2012relational}.

To improve the classification on tweets, one can make the system less domain independent by adding more Twitter-specific features, e.g., by utilizing automatic phrase-polarity lexicon extraction \citep{VelikovichEA:10}, or by adding lexica like the AFINN word list by~\cite{article:afinn} that is developed specifically for social media or the Twitter-oriented word lists created by~\cite{MohammadEA:13}.

While developing the visualisation application SentiMap, a wide use of Emojis was shown in the tweet stream. As the tweets were restricted by geographical location, most of them originated from hand held devices, such as Apple's iPhone. By translating these Emojis to common placeholders like $||Happy||$ or $||Sad||$, they could be used as features.