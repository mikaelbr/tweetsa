Twitter data are available through the Twitter API(!more). Some datasets from related research on the Twitter platform has also been made available for other research projects, as an alternative to collecting a complete data set from scratch. Some approaches specialize on certain domains, while others query for tweets containing emoticons (\emph{':)', ':)'}) to train a cross-domain classifier  (\cite{article:go}). The idea behind the emoticon approach is to make sure that the collected tweets contain subjectivity, but these training sets alone are limited to binary classification only (positive/negative classification).

After the data has been collected it should go through a filtering process. First, all non-english tweets are removed, then the Twitter specific symbols and functions described in Table ~\ref{tab:features} would normally be filtered out. As mentioned, a study by \cite{article:go} used ':)' and ':(' as a label for the polarity in their training data, and thus they did not remove these emoticons, but the URLs and usernames were replaced by a nomial ('URL' or 'USERNAME'). They also removed the query term from the text so it would not affect the classification.

\cite{article:omg} used a hashtagged data set (HASH) in addition to an emoticon data set (EMOT) from http://sentiment140.com. The hashtagged set is a subset of the Edinburgh Twitter corpus which consists of 97 million tweets (\cite{article:edinburgh}).

\begin{table}[]
\centering
\label{tab:features}
\begin{tabular}{|l|l|p{8cm}|}
\hline
RT & Retweet & Reposting another user’s tweet \\ \hline
@ & Mention & Tag used to mention another user \\ \hline
\# & Hashtag & Hashtags are used to tag a tweet to a certain topic. Have become popular recently, and is also used on other platforms \\ \hline
:),:-),$\wedge\wedge$ & Emoticon & Hashtags are used to tag a tweet to a certain topic. Have become popular recently, and is also used on other platforms \\ \hline
URL & URL & Typically a link to an external resource, e.g a new article or a photo \\ \hline
\end{tabular}
\caption{This table shows some of the features that are usually stripped.}
\end{table}

Some approaches has also experimented with normalizing the tweets, and removing redundant letters, e.g “loooove” and “crazyyy”, that are often used in tweets. Redundant letters like this are sometimes used to express a stronger sentiment, and it has therefore been experimented with trimming down to one additional redundant letter(‘loooove’ = ‘loove’ instead of love), so the stronger sentiment can be taken into consideration by a score/weight adjustment for that feature.

\subsubsection*{Part-of-speech tagging}
Part-Of-Speech (POS) tagging is a well-known process for marking the words of a sentence. Adjectives, adverbs and personal pronouns has shown good indicators for subjectivity, which has made POS tagging a good technique for filtering out objective tweets before the polarity classification. Early research on TSA showed that the challenging vocabulary made it harder to tag the tweets with a good accuracy. But in 2010 \cite{article:gimpel} made a POS tagger that aimed at marking tweets. It performed very well in their experiments (almost 90\% accuracy).

\subsubsection*{Subjectivity Classification}
The most used strategy for TSA is a two-step strategy where the first step is the subjectivity classification and the second step is the polarity classification. The goal for the subjectivity classification is to separate subjective and objective tweets.

One of the most used techniques for this task is POS tagging. \cite{article:pak} found several indicators on subjectivity by counting word frequencies in a subjective set vs an objective set. They found that utterances and personal pronouns were the strongest indicators on subjectivity in their set. \cite{article:jiang} used normalization, POS tagging, word stemming and syntactic parsing for the subjectivity classification task. The idea was that normalization of features would give better recall.

Previous research have also explored the use of noisy data and distant supervised methods such as emoticons and hashtags for the subjectivity classification, where any match from a given lexicon will classify the tweet as subjective.
